
@article{lucas_ising_2014,
	title = {Ising formulations of many {NP} problems},
	volume = {2},
	issn = {2296-424X},
	url = {https://www.frontiersin.org/journals/physics/articles/10.3389/fphy.2014.00005/full},
	doi = {10.3389/fphy.2014.00005},
	abstract = {{\textless}p{\textgreater}We provide Ising formulations for many NP-complete and NP-hard problems, including all of Karp's 21 NP-complete problems. This collects and extends mappings to the Ising model from partitioning, covering, and satisfiability. In each case, the required number of spins is at most cubic in the size of the problem. This work may be useful in designing adiabatic quantum optimization algorithms.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-10-14},
	journal = {Frontiers in Physics},
	author = {Lucas, Andrew},
	month = feb,
	year = {2014},
	note = {Publisher: Frontiers},
	keywords = {adiabatic quantum computation, Algorithms, complexity theory, NP, spin glasses},
}

@misc{moses_computational_2016,
	title = {Computational {Complexity} of {Arranging} {Music}},
	url = {http://arxiv.org/abs/1607.04220},
	doi = {10.48550/arXiv.1607.04220},
	abstract = {This paper proves that arrangement of music is NP-hard when subject to various constraints: avoiding musical dissonance, limiting how many notes can be played simultaneously, and limiting transition speed between chords. These results imply the computational complexity of related musical problems, including musical choreography and rhythm games.},
	urldate = {2024-11-09},
	publisher = {arXiv},
	author = {Moses, William S. and Demaine, Erik D.},
	month = jul,
	year = {2016},
	note = {arXiv:1607.04220},
	keywords = {Computer Science - Computational Complexity},
}

@article{huang_towards_2012,
	title = {Towards an automatic music arrangement framework using score reduction},
	volume = {8},
	issn = {1551-6857},
	url = {https://dl.acm.org/doi/10.1145/2071396.2071404},
	doi = {10.1145/2071396.2071404},
	abstract = {Score reduction is a process that arranges music for a target instrument by reducing original music. In this study we present a music arrangement framework that uses score reduction to automatically arrange music for a target instrument. The original music is first analyzed to determine the type of arrangement element of each section, then the phrases are identified and each is assigned a utility according to its type of arrangement element. For a set of utility-assigned phrases, we transform the music arrangement into an optimization problem and propose a phrase selection algorithm. The music is arranged by selecting appropriate phrases satisfying the playability constraints of a target instrument. Using the proposed framework, we implement a music arrangement system for the piano. An approach similar to Turing test is used to evaluate the quality of the music arranged by our system. The experiment results show that our system is able to create viable music for the piano.},
	number = {1},
	urldate = {2024-12-05},
	journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
	author = {Huang, Jiun-Long and Chiu, Shih-Chuan and Shan, Man-Kwan},
	month = feb,
	year = {2012},
	pages = {8:1--8:23},
}

@article{nakamura_statistical_2018,
	title = {Statistical piano reduction controlling performance difficulty},
	volume = {7},
	issn = {2048-7703},
	url = {https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/statistical-piano-reduction-controlling-performance-difficulty/EB23810939F49C01EBF8C64C57F3DCC2},
	doi = {10.1017/ATSIP.2018.18},
	abstract = {We present a statistical-modeling method for piano reduction, i.e.Â converting an ensemble score into piano scores, that can control performance difficulty. While previous studies have focused on describing the condition for playable piano scores, it depends on player's skill and can change continuously with the tempo. We thus computationally quantify performance difficulty as well as musical fidelity to the original score, and formulate the problem as optimization of musical fidelity under constraints on difficulty values. First, performance difficulty measures are developed by means of probabilistic generative models for piano scores and the relation to the rate of performance errors is studied. Second, to describe musical fidelity, we construct a probabilistic model integrating a prior piano-score model and a model representing how ensemble scores are likely to be edited. An iterative optimization algorithm for piano reduction is developed based on statistical inference of the model. We confirm the effect of the iterative procedure; we find that subjective difficulty and musical fidelity monotonically increase with controlled difficulty values; and we show that incorporating sequential dependence of pitches and fingering motion in the piano-score model improves the quality of reduction scores in high-difficulty cases.},
	language = {en},
	urldate = {2024-12-17},
	journal = {APSIPA Transactions on Signal and Information Processing},
	author = {Nakamura, Eita and Yoshii, Kazuyoshi},
	month = jan,
	year = {2018},
	keywords = {Automatic Music Arrangement, Statistical Modelling, Symbolic Music Processing},
	pages = {e13},
}

@misc{dong_towards_2021,
	title = {Towards {Automatic} {Instrumentation} by {Learning} to {Separate} {Parts} in {Symbolic} {Multitrack} {Music}},
	url = {http://arxiv.org/abs/2107.05916},
	doi = {10.48550/arXiv.2107.05916},
	abstract = {Modern keyboards allow a musician to play multiple instruments at the same time by assigning zones -- fixed pitch ranges of the keyboard -- to different instruments. In this paper, we aim to further extend this idea and examine the feasibility of automatic instrumentation -- dynamically assigning instruments to notes in solo music during performance. In addition to the online, real-time-capable setting for performative use cases, automatic instrumentation can also find applications in assistive composing tools in an offline setting. Due to the lack of paired data of original solo music and their full arrangements, we approach automatic instrumentation by learning to separate parts (e.g., voices, instruments and tracks) from their mixture in symbolic multitrack music, assuming that the mixture is to be played on a keyboard. We frame the task of part separation as a sequential multi-class classification problem and adopt machine learning to map sequences of notes into sequences of part labels. To examine the effectiveness of our proposed models, we conduct a comprehensive empirical evaluation over four diverse datasets of different genres and ensembles -- Bach chorales, string quartets, game music and pop music. Our experiments show that the proposed models outperform various baselines. We also demonstrate the potential for our proposed models to produce alternative convincing instrumentations for an existing arrangement by separating its mixture into parts. All source code and audio samples can be found at https://salu133445.github.io/arranger/ .},
	urldate = {2024-12-17},
	publisher = {arXiv},
	author = {Dong, Hao-Wen and Donahue, Chris and Berg-Kirkpatrick, Taylor and McAuley, Julian},
	month = oct,
	year = {2021},
	note = {arXiv:2107.05916 [cs]},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: ISMIR 2021 camera ready},
}

@book{miranda_quantum_2022,
	title = {Quantum {Computer} {Music}: {Foundations}, {Methods} and {Advanced} {Concepts}},
	copyright = {https://www.springer.com/tdm},
	isbn = {978-3-031-13908-6 978-3-031-13909-3},
	shorttitle = {Quantum {Computer} {Music}},
	url = {https://link.springer.com/10.1007/978-3-031-13909-3},
	language = {en},
	urldate = {2024-12-28},
	publisher = {Springer International Publishing},
	editor = {Miranda, Eduardo Reck},
	year = {2022},
	doi = {10.1007/978-3-031-13909-3},
	keywords = {Artificial Intelligence and Music, Computer Music, Computer-aided Music Composition, IBM Quantum, Music Technology, Photonic Quantum Computing, Qiskit, Quantum AI, Quantum Artificial Intelligence, Quantum Arts, Quantum Computer, Quantum Computer Music, Quantum Computing, Quantum Computing and Creativity, Quantum Creativity, Quantum Music, Rigetti, Xanadu},
}


@inproceedings{terao_neural_2023,
	title = {Neural {Band}-to-{Piano} {Score} {Arrangement} with {Stepless} {Difficulty} {Control}},
	url = {https://ieeexplore.ieee.org/abstract/document/10095462?casa_token=8Hedd-Wd_ScAAAAA:pYVnW7EXHUaiTkWs-tRs7WX2G8xVuygmtQZSYJK087eUVoWy5KCEM7WYN_egZTn_ixtwxSr8Sog},
	doi = {10.1109/ICASSP49357.2023.10095462},
	abstract = {This paper describes a music arrangement method of popular music that can convert a band score into a piano score with a steplessly-specified level of performance difficulty. The basic strategy of band-to-piano score arrangement is to select notes from an augmented band score obtained by up- and down-shifting the notes of an original band score by one octave. Given band scores and the corresponding piano scores with elementary- and advanced-levels, one can train a deep neural network (DNN) that estimates note masks conditioned by the difficulty levels. Conditioned by an intermediate level at runtime, however, the DNN tends to generate an advanced-level score. To solve this problem, assuming that an easier piano score is a subset of harder one, we estimate the basic importance of each note with a difficulty-agnostic DNN and then warp it with a power function depending on a specified difficulty level. To achieve the fine controllability of the difficulty level, we propose a training method that subjects the DNN to generating piano scores with various intermediate levels, where the note-level loss for those scores is evaluated using only the ground-truth elementary- and advanced-level scores. Considering the non-uniqueness of piano arrangement, the statistic-level loss with respect to the note density and polyphony level is also computed according to the given levels. The experimental results showed that the proposed method attained both the performance gain and the stepless difficulty control.},
	urldate = {2024-12-17},
	booktitle = {{ICASSP} 2023 - 2023 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Terao, Moyu and Nakamura, Eita and Yoshii, Kazuyoshi},
	month = jun,
	year = {2023},
	note = {ISSN: 2379-190X},
	keywords = {Automatic piano arrangement, Controllability, deep learning, Deep learning, Neural networks, Performance gain, Runtime, score reduction, Signal processing, symbolic music processing, Training},
	pages = {1--5},
}


@misc{oed_annealing_2024,
	title = {annealing, n., sense 3},
	url = {https://doi.org/10.1093/OED/1128035865},
	publisher = {Oxford University Press},
	author = {{Oxford English Dictionary}},
	month = dec,
	year = {2024},
}


@misc{musicxml,
	title = {{MusicXML} for {Exchanging} {Digital} {Sheet} {Music}},
	url = {https://www.musicxml.com/},
	abstract = {MusicXML is the standard open format for exchanging digital sheet music. It allows you to collaborate with musicians using different music applications.},
	language = {en-US},
	urldate = {2024-12-28},
	journal = {MusicXML},
}


@inproceedings{hoshi_versatile_2022,
	title = {Versatile {Automatic} {Piano} {Reduction} {Generation} {System} by {Deep} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9754115},
	doi = {10.1109/ICARC54489.2022.9754115},
	abstract = {Piano reduction is a sheet music that is arranged for piano performance while retaining as much information as possible on a song composed of multiple parts, such as an orchestra. There have been several studies on automatic generation of piano reductions. However, they have had difficulties in dealing with a wide range of genres because they are generated according to predefined rules. Therefore, in this study, we propose a method for automatic generation of piano reduction with enhanced versatility using deep learning. In this system, a CNN-based supervised learning model is used to generate a piano-playable score from a song consisting of multiple parts. We also proposed an algorithm to discriminate the playability of a sheet on the piano and tried to improve the accuracy of the piano reduction. As a result of the evaluation of the generated piano reduction, it was found that the playability was improved.},
	urldate = {2024-12-27},
	booktitle = {2022 2nd {International} {Conference} on {Advanced} {Research} in {Computing} ({ICARC})},
	author = {Hoshi, Yuki and Orihara, Ryohei and Sei, Yuichi and Tahara, Yasuyuki and Ohsuga, Akihiko},
	month = feb,
	year = {2022},
	keywords = {Deep learning, Training, Instruments, CNN, Error analysis, Machine learning, MIDI, Music, Neural nets, Piano reduction, Supervised learning, Training data},
	pages = {66--71},
}


@inproceedings{pearce_towards_2001,
	title = {Towards {A} {Framework} for the {Evaluation} of {Machine} {Compositions}},
	url = {https://www.semanticscholar.org/paper/Towards-A-Framework-for-the-Evaluation-of-Machine-Pearce-Wiggins/c1cb675ecddaf28f2c241921bb16399a1a9e19c9?sort=is-influential},
	abstract = {We outline a framework within which machine compositions may be evaluated objectively. In particular, the framework allows statements about those compositions to be refuted on the basis of empirical experimentation. We consider this to be fundamental if we wish to evaluate the degree to which our programs achieve their compositional aims. Furthermore, a review of the literature reveals that this is a largely ignored aspect of research into algorithmic composition. Our framework involves four components: specifying the compositional aims; inducing a critic from a set of example musical phrases; composing music that satisfies the critic; and evaluating specific claims about the compositions in experiments using human subjects. We describe a system which exemplifies these four stages and which demonstrates the practicality of the framework. Finally, the application of the framework to the evaluation of musical creativity is discussed and directions for future research are suggested.},
	urldate = {2024-11-25},
	author = {Pearce, M. and Wiggins, Geraint A.},
	year = {2001},
}


@misc{freedline_algorhythms_2021,
	title = {Algorhythms: {Generating} {Music} with {D}-{Wave}'s {Quantum} {Annealer}},
	shorttitle = {Algorhythms},
	url = {https://medium.com/mit-6-s089-intro-to-quantum-computing/algorhythms-generating-music-with-d-waves-quantum-annealer-95697ec23ccd},
	abstract = {In this Blog we will be discussing our project for the iQuHack 2021 Hackathon.},
	language = {en},
	urldate = {2024-11-09},
	journal = {MIT 6.s089âIntro to Quantum Computing},
	author = {Freedline, Alex},
	month = feb,
	year = {2021},
}


@misc{arya_music_2022,
	title = {Music {Composition} {Using} {Quantum} {Annealing}},
	url = {http://arxiv.org/abs/2201.10557},
	doi = {10.48550/arXiv.2201.10557},
	abstract = {With the emergence of quantum computers, a new field of algorithmic music composition has been initiated. The vast majority of previous work focuses on music generation using gate-based quantum computers. An alternative model of computation is adiabatic quantum computing (AQC), and a heuristic algorithm known as quantum annealing running in the framework of AQC is a promising method for solving optimization problems. In this chapter, we lay the groundwork of music composition using quantum annealing. We approach the process of music composition as an optimization problem. We describe the fundamental methodologies needed for generating different aspects of music including melody, rhythm, and harmony. The discussed techniques are illustrated through examples to ease the understanding. The music pieces generated using D-Wave quantum annealers are among the first examples of their kind and presented within the scope of the chapter. The text is an unedited pre-publication version of a chapter which will appear in the book "Quantum Computer Music", Miranda, E. R. (Editor).},
	urldate = {2024-10-26},
	publisher = {arXiv},
	author = {Arya, Ashish and Botelho, Ludmila and CaÃ±ete, Fabiola and Kapadia, Dhruvi and Salehi, Ãzlem},
	month = jan,
	year = {2022},
	note = {arXiv:2201.10557},
	keywords = {Quantum Physics, Computer Science - Emerging Technologies},
}


@misc{miranda_hello_2020,
	title = {Quantum {Computer}: {Hello}, {Music}!},
	shorttitle = {Quantum {Computer}},
	url = {http://arxiv.org/abs/2006.13849},
	doi = {10.48550/arXiv.2006.13849},
	abstract = {Quantum computing is emerging as a promising technology, which is built on the principles of subatomic physics. By the time of writing, fully fledged practical quantum computers are not widely available. But research and development are advancing rapidly. Various software simulators are already available. And a few companies have already started to provide access to quantum hardware via the cloud. These initiatives have enabled experiments with quantum computing to tackle some realistic problems in science; e.g., in chemistry and cryptography. In spite of continuing progress in developing increasingly more sophisticated hardware and software, research in quantum computing has been focusing primarily on developing scientific applications. Up till now there has been virtually no research activity aimed at widening the range of applications of this technology beyond science and engineering. In particular applications for the entertainment industry and creative economies. This article introduces a new field of research, which is referred to as Quantum Computer Music. This research is aimed at the development of quantum computing tools and approaches to creating, performing, listening to and distributing music. The article begins with a brief historical background. Then, it introduces the notion of algorithmic music and presents two quantum computer music systems: a singing voice synthesiser and a musical sequencer based on quantum walk. A primer on quantum computing is also given. The chapter ends with a concluding discussion and advice for further work to develop this new exciting area of research.},
	urldate = {2024-10-24},
	publisher = {arXiv},
	author = {Miranda, Eduardo R.},
	month = jun,
	year = {2020},
	note = {arXiv:2006.13849},
	keywords = {Quantum Physics, Computer Science - Emerging Technologies, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}


@misc{miranda_impossible_2022,
	title = {Teaching {Qubits} to {Sing}: {Mission} {Impossible}?},
	shorttitle = {Teaching {Qubits} to {Sing}},
	url = {http://arxiv.org/abs/2207.08225},
	doi = {10.48550/arXiv.2207.08225},
	abstract = {This paper introduces a system that learns to sing new tunes by listening to examples. It extracts sequencing rules from input music and uses these rules to generate new tunes, which are sung by a vocal synthesiser. We developed a method to represent rules for musical composition as quantum circuits. We claim that such musical rules are quantum native: they are naturally encodable in the amplitudes of quantum states. To evaluate a rule to generate a subsequent event, the system builds the respective quantum circuit dynamically and measures it. After a brief discussion about the vocal synthesis methods that we have been experimenting with, the paper introduces our novel generative music method through a practical example. The paper shows some experiments and concludes with a discussion about harnessing the creative potential of the system.},
	urldate = {2024-10-29},
	publisher = {arXiv},
	author = {Miranda, Eduardo Reck and Siegelwax, Brian N.},
	month = aug,
	year = {2022},
	note = {arXiv:2207.08225},
	keywords = {Quantum Physics, Computer Science - Artificial Intelligence},
}
